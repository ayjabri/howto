{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from imblearn import over_sampling,under_sampling\n",
    "from torchsampler import ImbalancedDatasetSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/Aymanjabri/notebooks/Artwork/data/images/images'\n",
    "x = glob(path+'/**/*')\n",
    "\n",
    "classes = [os.path.basename(i) for i in glob(path+'/**')]\n",
    "targets = np.arange(0,50)\n",
    "class_to_idx=dict(zip(classes,targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = [os.path.basename(os.path.dirname(i)) for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [class_to_idx[i] for i in d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 84,\n",
       " 1: 128,\n",
       " 2: 702,\n",
       " 3: 43,\n",
       " 4: 291,\n",
       " 5: 99,\n",
       " 6: 259,\n",
       " 7: 49,\n",
       " 8: 194,\n",
       " 9: 255,\n",
       " 10: 90,\n",
       " 11: 119,\n",
       " 12: 181,\n",
       " 13: 81,\n",
       " 14: 87,\n",
       " 15: 31,\n",
       " 16: 134,\n",
       " 17: 188,\n",
       " 18: 311,\n",
       " 19: 73,\n",
       " 20: 239,\n",
       " 21: 164,\n",
       " 22: 81,\n",
       " 23: 126,\n",
       " 24: 47,\n",
       " 25: 91,\n",
       " 26: 139,\n",
       " 27: 70,\n",
       " 28: 88,\n",
       " 29: 117,\n",
       " 30: 877,\n",
       " 31: 59,\n",
       " 32: 193,\n",
       " 33: 186,\n",
       " 34: 120,\n",
       " 35: 439,\n",
       " 36: 24,\n",
       " 37: 336,\n",
       " 38: 102,\n",
       " 39: 141,\n",
       " 40: 67,\n",
       " 41: 55,\n",
       " 42: 137,\n",
       " 43: 171,\n",
       " 44: 109,\n",
       " 45: 262,\n",
       " 46: 143,\n",
       " 47: 70,\n",
       " 48: 66,\n",
       " 49: 328}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balance = dict(sorted(Counter(y).items()));balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 36)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanceList = list(balance.values())\n",
    "max_idx = balanceList.index(max(balanceList))\n",
    "min_idx = balanceList.index(min(balanceList))\n",
    "max_idx,min_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vincent_van_Gogh\n",
      "Jackson_Pollock\n"
     ]
    }
   ],
   "source": [
    "print(classes[max_idx]) #The class with the most samples\n",
    "print(classes[min_idx]) #The class with least number of samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Balance the sample using Random Over Sampling\n",
    "\n",
    "let's balance our data by synthetically generate additional number of minority classes' painting to match the majority class sample number. \n",
    "\n",
    "In this case the max number of samples across classes is 877 paintings by Van Gogh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "over = over_sampling.RandomOverSampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance.fit_resample(x,y)\n",
    "X = np.array(x).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled,y_resampled=over.fit_resample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 877),\n",
       " (1, 877),\n",
       " (2, 877),\n",
       " (3, 877),\n",
       " (4, 877),\n",
       " (5, 877),\n",
       " (6, 877),\n",
       " (7, 877),\n",
       " (8, 877),\n",
       " (9, 877),\n",
       " (10, 877),\n",
       " (11, 877),\n",
       " (12, 877),\n",
       " (13, 877),\n",
       " (14, 877),\n",
       " (15, 877),\n",
       " (16, 877),\n",
       " (17, 877),\n",
       " (18, 877),\n",
       " (19, 877),\n",
       " (20, 877),\n",
       " (21, 877),\n",
       " (22, 877),\n",
       " (23, 877),\n",
       " (24, 877),\n",
       " (25, 877),\n",
       " (26, 877),\n",
       " (27, 877),\n",
       " (28, 877),\n",
       " (29, 877),\n",
       " (30, 877),\n",
       " (31, 877),\n",
       " (32, 877),\n",
       " (33, 877),\n",
       " (34, 877),\n",
       " (35, 877),\n",
       " (36, 877),\n",
       " (37, 877),\n",
       " (38, 877),\n",
       " (39, 877),\n",
       " (40, 877),\n",
       " (41, 877),\n",
       " (42, 877),\n",
       " (43, 877),\n",
       " (44, 877),\n",
       " (45, 877),\n",
       " (46, 877),\n",
       " (47, 877),\n",
       " (48, 877),\n",
       " (49, 877)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(Counter(y_resampled).items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43850, 8446)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_resampled),len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The over-resamled data `X_resample` and `y_resample` now has the max number of samples across classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Balance the sample using Random *Under* Sampling\n",
    "\n",
    "To balance our data by reducing the number of samples to match the minority class, which in this case is 'Jackson_Pollock' with 24 paintings only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "under = under_sampling.RandomUnderSampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(x).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_u,y_u=under.fit_resample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 24),\n",
       " (1, 24),\n",
       " (2, 24),\n",
       " (3, 24),\n",
       " (4, 24),\n",
       " (5, 24),\n",
       " (6, 24),\n",
       " (7, 24),\n",
       " (8, 24),\n",
       " (9, 24),\n",
       " (10, 24),\n",
       " (11, 24),\n",
       " (12, 24),\n",
       " (13, 24),\n",
       " (14, 24),\n",
       " (15, 24),\n",
       " (16, 24),\n",
       " (17, 24),\n",
       " (18, 24),\n",
       " (19, 24),\n",
       " (20, 24),\n",
       " (21, 24),\n",
       " (22, 24),\n",
       " (23, 24),\n",
       " (24, 24),\n",
       " (25, 24),\n",
       " (26, 24),\n",
       " (27, 24),\n",
       " (28, 24),\n",
       " (29, 24),\n",
       " (30, 24),\n",
       " (31, 24),\n",
       " (32, 24),\n",
       " (33, 24),\n",
       " (34, 24),\n",
       " (35, 24),\n",
       " (36, 24),\n",
       " (37, 24),\n",
       " (38, 24),\n",
       " (39, 24),\n",
       " (40, 24),\n",
       " (41, 24),\n",
       " (42, 24),\n",
       " (43, 24),\n",
       " (44, 24),\n",
       " (45, 24),\n",
       " (46, 24),\n",
       " (47, 24),\n",
       " (48, 24),\n",
       " (49, 24)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(Counter(y_u).items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 8446)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_u),len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new data `X_u` and `y_u` now has the same number of sample acros classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Balance the sample using torchsampler\n",
    "\n",
    "Experementing this new sampler that I found on github.\n",
    "\n",
    "The calim is that it doesn't augment the data but rather samples it in a balanced way. that being said, it means we need to create the `DataLoader` then iter through it to see if it really works. \n",
    "\n",
    "P.S it doesn't work with `TensorData`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['/Users/Aymanjabri/notebooks/Artwork/data/images/images/Piet_Mondrian/Piet_Mondrian_38.jpg',\n",
       "  '/Users/Aymanjabri/notebooks/Artwork/data/images/images/Piet_Mondrian/Piet_Mondrian_10.jpg',\n",
       "  '/Users/Aymanjabri/notebooks/Artwork/data/images/images/Piet_Mondrian/Piet_Mondrian_11.jpg',\n",
       "  '/Users/Aymanjabri/notebooks/Artwork/data/images/images/Piet_Mondrian/Piet_Mondrian_39.jpg',\n",
       "  '/Users/Aymanjabri/notebooks/Artwork/data/images/images/Piet_Mondrian/Piet_Mondrian_13.jpg'],\n",
       " [0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:5],y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArtworkSet(Dataset):\n",
    "    def __init__(self,x,y,class_to_idx,classes,transform=None):\n",
    "        self.classes = classes\n",
    "        self.class_to_idx = class_to_idx\n",
    "        self.paths = x\n",
    "        self.targets = y\n",
    "        self.transform=transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        img,label = Image.open(self.paths[idx][0]),self.targets[idx]\n",
    "        if img.getbands()[0] == 'L':\n",
    "            img = img.convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = ArtworkSet(x,y,class_to_idx,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-efa9c913cda6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m trainloader = DataLoader(trainset,batch_size=50,\n\u001b[0;32m----> 2\u001b[0;31m                          sampler=ImbalancedDatasetSampler(trainset)) #for some reason it doesn't work here as well!!\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/Pytorch/lib/python3.7/site-packages/torchsampler/imbalanced.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, indices, num_samples, callback_get_label)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mlabel_to_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabel_to_count\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mlabel_to_count\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Pytorch/lib/python3.7/site-packages/torchsampler/imbalanced.py\u001b[0m in \u001b[0;36m_get_label\u001b[0;34m(self, dataset, idx)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainloader = DataLoader(trainset,batch_size=50,\n",
    "                         sampler=ImbalancedDatasetSampler(trainset)) #for some reason it doesn't work here as well!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Adjust loss function weights\n",
    "\n",
    "An easy way is to adjust loss function such that it over-punishes errors in predicting minority classes.\n",
    "\n",
    "`CrossEntropyLoss` has already a builtin weight function that we can use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.99455363,  1.5155103 ,  8.31162681,  0.50911674,  3.44541795,\n",
       "        1.1721525 ,  3.06654037,  0.58015629,  2.2969453 ,  3.01918068,\n",
       "        1.06559318,  1.40895098,  2.14302628,  0.95903386,  1.03007341,\n",
       "        0.36703765,  1.58654985,  2.22590575,  3.68221643,  0.86431447,\n",
       "        2.82974189,  1.94174757,  0.95903386,  1.49183045,  0.55647644,\n",
       "        1.0774331 ,  1.64574947,  0.8287947 ,  1.04191333,  1.38527113,\n",
       "       10.38361354,  0.69855553,  2.28510538,  2.20222591,  1.42079091,\n",
       "        5.19772673,  0.28415818,  3.97821454,  1.20767227,  1.66942932,\n",
       "        0.79327492,  0.65119583,  1.62206962,  2.02462704,  1.29055174,\n",
       "        3.10206015,  1.69310916,  0.8287947 ,  0.781435  ,  3.88349515])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_weights = np.bincount(y)/len(y)*100;curr_weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.0110, 1.3197, 0.2406, 3.9284, 0.5805, 1.7063, 0.6522, 3.4473, 0.8707,\n",
       "        0.6624, 1.8769, 1.4195, 0.9333, 2.0854, 1.9416, 5.4490, 1.2606, 0.8985,\n",
       "        0.5432, 2.3140, 0.7068, 1.0300, 2.0854, 1.3406, 3.5940, 1.8563, 1.2153,\n",
       "        2.4131, 1.9195, 1.4438, 0.1926, 2.8631, 0.8752, 0.9082, 1.4077, 0.3848,\n",
       "        7.0383, 0.5027, 1.6561, 1.1980, 2.5212, 3.0713, 1.2330, 0.9878, 1.5497,\n",
       "        0.6447, 1.1813, 2.4131, 2.5594, 0.5150], dtype=torch.float64)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#because we have 50 classes. the goal is to have a 2% representation of each classes in the dataset (100/50)\n",
    "#To achieve that we divid 2/current_weights \n",
    "weights = torch.tensor(2/curr_weights);weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "loss_fn = nn.CrossEntropyLoss(weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
